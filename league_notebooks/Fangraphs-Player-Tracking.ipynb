{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking Single Players on Fangraphs\n",
    "\n",
    "### MSP 8.5.2017\n",
    "\n",
    "Can the fangraphs page be readable smoothly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>code_show=true; function code_toggle() { if (code_show){ $('div.input').hide();} else { $('div.input').show(); } code_show = !code_show} $( document ).ready(code_toggle);</script><form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>code_show=true; function code_toggle() { if (code_show){ $('div.input').hide();} else { $('div.input').show(); } code_show = !code_show} $( document ).ready(code_toggle);</script><form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# boilerplate imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports for scraping\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "# basic birth year reader. tables[1] has good stuff in it!\n",
    "def get_birth_year(tables):\n",
    "\n",
    "    birthdate_start = (tables[1].text).find(\"Birthdate:\")\n",
    "\n",
    "    birthdate_end =  (tables[1].text).find('(',birthdate_start)\n",
    "\n",
    "    #print (tables[1].text)[birthdate_start:birthdate_end]\n",
    "    birth_year = (tables[1].text)[birthdate_start:birthdate_end].split('/')[2]\n",
    "    #print birth_year\n",
    "    \n",
    "    return birth_year\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the listing of the teams of interest (all!)\n",
    "\n",
    "teams = ['angels','astros','athletics','bluejays','braves',\\\n",
    "        'brewers','cardinals','cubs','diamondbacks','dodgers',\\\n",
    "        'giants','indians','mariners','marlins','mets','nationals',\\\n",
    "        'orioles','padres','phillies','pirates','rangers',\\\n",
    "        'rays','redsox','rockies','royals','tigers','twins',\\\n",
    "        'whitesox','yankees']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Hitters\n",
    "\n",
    "This cell only needs to be run in the event that player ID numbers change, or new players are added."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#\n",
    "# make hitter dictionary\n",
    "#\n",
    "HDict = {}\n",
    "\n",
    "\n",
    "for team in teams:\n",
    "    \n",
    "    print team,\n",
    "    \n",
    "    get_url = 'http://www.fangraphs.com/teams/'+team#angels'\n",
    "\n",
    "    r  = requests.get(get_url)\n",
    "\n",
    "    data = r.text\n",
    "\n",
    "    soup = BeautifulSoup(data)\n",
    "\n",
    "    tables = soup.findAll('table')\n",
    "\n",
    "\n",
    "    for row in tables[5].find_all(\"tr\")[1:]: \n",
    "    \n",
    "        sav = [td.find('a') for td in row.find_all(\"td\")][0]\n",
    "    \n",
    "        try:\n",
    "            need_url = sav.get('href')\n",
    "        \n",
    "            HDict[sav.text] = need_url[(need_url).find('playerid')+9:(need_url).find('&')]\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "f = open('data/batterdict.dat','w')\n",
    "\n",
    "for entry in HDict.keys():\n",
    "    try:\n",
    "        print >>f,entry,'|',HDict[entry]\n",
    "    except:\n",
    "        print entry,'|',HDict[entry]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 821 hitters by scraping teams.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "HDict = {}\n",
    "\n",
    "f = open('data/batterdict.dat')\n",
    "\n",
    "for line in f:\n",
    "    #print line\n",
    "    try:\n",
    "        HDict[(line.split('|')[0]).strip()] = line.split('|')[1]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "print('Found {} hitters by scraping teams.'.format(len(HDict.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Pitchers\n",
    "\n",
    "This cell only needs to be run in the event that player ID numbers change, or new players are added."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#\n",
    "# make pitcher dictionary\n",
    "#\n",
    "PDict = {}\n",
    "\n",
    "\n",
    "for team in teams:\n",
    "    \n",
    "    print team,\n",
    "    \n",
    "    get_url = 'http://www.fangraphs.com/teams/'+team#angels'\n",
    "\n",
    "    r  = requests.get(get_url)\n",
    "\n",
    "    data = r.text\n",
    "\n",
    "    soup = BeautifulSoup(data)\n",
    "\n",
    "    tables = soup.findAll('table')\n",
    "\n",
    "\n",
    "    for row in tables[6].find_all(\"tr\")[1:]: \n",
    "    \n",
    "        sav = [td.find('a') for td in row.find_all(\"td\")][0]\n",
    "    \n",
    "        try:\n",
    "            need_url = sav.get('href')\n",
    "        \n",
    "            PDict[sav.text] = need_url[(need_url).find('playerid')+9:(need_url).find('&')]\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #print need_url\n",
    "    #print need_url[(need_url).find('playerid')+9:(need_url).find('&')]\n",
    "    #print sav.text\n",
    "\n",
    "    \n",
    "#print PDict\n",
    "\n",
    "f = open('data/pitcherdict.dat','w')\n",
    "\n",
    "for entry in PDict.keys():\n",
    "    try:\n",
    "        print >>f,entry,'|',PDict[entry]\n",
    "    except:\n",
    "        print entry,'|',PDict[entry]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 648 pitchers by scraping teams.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PDict = {}\n",
    "\n",
    "f = open('data/pitcherdict.dat')\n",
    "\n",
    "for line in f:\n",
    "    #print line\n",
    "    try:\n",
    "        PDict[(line.split('|')[0]).strip()] = line.split('|')[1]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "print('Found {} pitchers by scraping teams.'.format(len(PDict.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Application: Aging Curves\n",
    "\n",
    "For pitchers, how does K/9 evolve with age?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# for an individual player\n",
    "#'\n",
    "\n",
    "itable = [u'Season', u'Team', u'W', u'L', u'SV', u'G', u'GS', \\\n",
    "          u'IP', u'K/9', u'BB/9', u'HR/9', u'BABIP', u'LOB%', \\\n",
    "          u'GB%', u'HR/FB', u'ERA', u'FIP', u'xFIP', u'WAR']\n",
    "#             0         1        2    3     4      5     6  \\\n",
    "#            7      8       9       10       11          12     \\\n",
    "#            13     14       15       16       17      18\n",
    "\n",
    "\n",
    "# these are categories to eliminate\n",
    "projections = ['Depth Charts','Fans (14)','Steamer','Fans (12)'\\\n",
    "               'ZiPS', 'ZiPS (R)','Steamer (R)','Depth Charts (R)','Average','Postseason']\n",
    "\n",
    "minors = ['(AA)','(A)','(AAA)','(R)','(A+)','(A-)']\n",
    "\n",
    "agg = ['Total','Postseason']\n",
    "\n",
    "\n",
    "# now make a dictionary\n",
    "PVals = {}\n",
    "\n",
    "for player in PDict.keys()[0:20]:\n",
    "    PVals[player] = {}\n",
    "    #print player\n",
    "\n",
    "    get_url = 'http://www.fangraphs.com/statss.aspx?playerid='+str(PDict[player].strip())\n",
    "\n",
    "    r  = requests.get(get_url)\n",
    "\n",
    "    data = r.text\n",
    "\n",
    "    soup = BeautifulSoup(data)\n",
    "\n",
    "    tables = soup.findAll('table')\n",
    "\n",
    "    birth_year = float(get_birth_year(tables))\n",
    "\n",
    "    PVals[player]['age'] = []\n",
    "    PVals[player]['k9'] = []\n",
    "\n",
    "    for indx,table in enumerate(tables):\n",
    "\n",
    "        #print indx,[th.get_text() for th in table.find(\"tr\").find_all(\"th\")]\n",
    "   \n",
    "        if [th.get_text() for th in table.find(\"tr\").find_all(\"th\")] == itable:\n",
    "        \n",
    "            #print get_url\n",
    "            print player\n",
    "        \n",
    "            #print [th.get_text() for th in table.find(\"tr\").find_all(\"th\")]\n",
    "        \n",
    "            for row in table.find_all(\"tr\")[1:]:\n",
    "\n",
    "                print row.findAll(\"td\", class_=\"rgRow grid_postseason\"})\n",
    "                sav = [td.get_text() for td in row.find_all(\"td\")]\n",
    "            \n",
    "                if (sav[1] not in projections) & \\\n",
    "                (np.sum([(x in sav[1]) for x in minors])==0) & \\\n",
    "                (np.sum([(x in sav[0]) for x in agg])==0): \n",
    "                    #print \"'\"+sav[-1]+\"'\"\n",
    "                    \n",
    "                    # current problem is that postseason is mixed in\n",
    "                    \n",
    "                    if (float(sav[8]) > 0.) & (float(sav[7])>50.) & (sav[-1]!=' '):\n",
    "                        PVals[player]['age'].append(float(sav[0])-birth_year)\n",
    "                        PVals[player]['k9'].append(float(sav[8]))\n",
    "                    #if (float(sav[7])<50.):\n",
    "                    #    print 'rejected for too few innings:',sav[0],float(sav[7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,3))\n",
    "\n",
    "for player in PVals.keys():\n",
    "    plt.plot(PVals[player]['age'],PVals[player]['k9'],color='black')\n",
    "\n",
    "plt.xlabel('Age',size=18)\n",
    "plt.ylabel('K/9',size=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pval in PVals.keys(): print pval,PVals[pval]['age'],PVals[pval]['k9']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate the different rows that are available for extracting year-on-year stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# for an individual player\n",
    "#\n",
    "\n",
    "player = 'Brad Peacock'\n",
    "\n",
    "\n",
    "get_url = 'http://www.fangraphs.com/statss.aspx?playerid='+str(PDict[player].strip())\n",
    "\n",
    "get_url = 'http://www.fangraphs.com/statss.aspx?playerid=5401'\n",
    "\n",
    "\n",
    "\n",
    "projections = ['Depth Charts','Fans (14)','Steamer',\\\n",
    "               'ZiPS', 'ZiPS (R)','Steamer (R)','Depth Charts (R)','Average']\n",
    "\n",
    "minors = ['(AA)','(A)','(AAA)','(R)','(A+)','(A-)']\n",
    "\n",
    "agg = ['Total']\n",
    "\n",
    "r  = requests.get(get_url)\n",
    "\n",
    "data = r.text\n",
    "\n",
    "soup = BeautifulSoup(data)\n",
    "\n",
    "\n",
    "tables = soup.findAll('table')\n",
    "\n",
    "birth_year = float(get_birth_year(tables))\n",
    "\n",
    "age = []\n",
    "k9 = []\n",
    "\n",
    "for indx,table in enumerate(tables):\n",
    "\n",
    "    print indx,[th.get_text() for th in table.find(\"tr\").find_all(\"th\")]\n",
    "   \n",
    "    if indx==10:\n",
    "        \n",
    "        #print [th.get_text() for th in table.find(\"tr\").find_all(\"th\")]\n",
    "        \n",
    "        for row in table.find_all(\"tr\")[1:]:\n",
    "            sav = [td.get_text() for td in row.find_all(\"td\")]\n",
    "            #if (sav[0]=='2017') & (sav[1] not in projections) & (minors not in sav[1]): print sav\n",
    "            if (sav[1] not in projections) & \\\n",
    "            (np.sum([(x in sav[1]) for x in minors])==0) & \\\n",
    "            (np.sum([(x in sav[0]) for x in agg])==0): \n",
    "                age.append(float(sav[0])-birth_year)\n",
    "                k9.append(float(sav[2]))\n",
    "            #print sav[1],np.sum([(x in sav[1]) for x in minors]),\n",
    "    #        #print sav[0]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the ability to automatically grab the stat page for any player!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
